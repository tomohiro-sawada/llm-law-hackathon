# LLM Law Hackathon 

We are finetuning MPT-7B base on biglaw and pile of law. (We are not using biglaw since pile of law already takes 30 hours to tokenize.) As per Miguel's suggestion, we are going to combine this with MPT-7B Instruct (by taking convex combinations of the weights). 


- [Baseten](https://github.com/basetenlabs/falcon-7b-truss)
- [Falcon](https://github.com/basetenlabs/falcon-7b-truss) 
- [Storywriter Script](https://github.com/rmihaylov/mpttune)


